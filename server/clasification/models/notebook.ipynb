{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import TFIDF, MultinomialNaiveBayes, SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7ToChNPQeaN7"
      },
      "outputs": [],
      "source": [
        "lyrics = []\n",
        "label = []\n",
        "title = []\n",
        "artist = []\n",
        "\n",
        "with open(\"dataset/clean_dataset.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for doc in reader:\n",
        "        lyrics.append(doc[\"lyrics\"])\n",
        "        label.append(int(doc[\"label\"]))\n",
        "        title.append(doc[\"song_name\"])\n",
        "        artist.append(doc[\"artist\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t_3np0Oeesp0"
      },
      "outputs": [],
      "source": [
        "def case_folding(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(doc.lower())\n",
        "    return temp\n",
        "\n",
        "\n",
        "def normalization(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(\" \".join(re.findall(r\"[a-zA-Z]+\", doc)))\n",
        "    return temp\n",
        "\n",
        "\n",
        "def tokenization(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(doc.split())\n",
        "    return temp\n",
        "\n",
        "\n",
        "def stopword_removal(list_of_tokenize_doc):\n",
        "    result = []\n",
        "    stopwords = [\n",
        "        \"ada\", \"adalah\", \"adanya\", \"adapun\", \"agak\", \"agaknya\", \"agar\", \"akan\", \"akankah\", \"akhir\", \"akhiri\", \"akhirnya\", \"aku\", \"akulah\", \"amat\", \"amatlah\", \"anda\", \"andalah\", \"antar\", \"antara\", \"antaranya\", \"apa\", \"apaan\", \"apabila\", \"apakah\", \"apalagi\", \"apatah\", \"artinya\", \"asal\", \"asalkan\", \"atas\", \"atau\", \"ataukah\", \"ataupun\", \"awal\", \"awalnya\", \"bagai\", \"bagaikan\", \"bagaimana\", \"bagaimanakah\", \"bagaimanapun\", \"bagi\", \"bagian\", \"bahkan\", \"bahwa\", \"bahwasanya\", \"baik\", \"bakal\", \"bakalan\", \"balik\", \"banyak\", \"bapak\", \"baru\", \"bawah\", \"beberapa\", \"begini\", \"beginian\", \"beginikah\", \"beginilah\", \"begitu\", \"begitukah\", \"begitulah\", \"begitupun\", \"bekerja\", \"belakang\", \"belakangan\", \"belum\", \"belumlah\", \"benar\", \"benarkah\", \"benarlah\", \"berada\", \"berakhir\", \"berakhirlah\", \"berakhirnya\", \"berapa\", \"berapakah\", \"berapalah\", \"berapapun\", \"berarti\", \"berawal\", \"berbagai\", \"berdatangan\", \"beri\", \"berikan\", \"berikut\", \"berikutnya\", \"berjumlah\", \"berkali-kali\", \"berkata\", \"berkehendak\", \"berkeinginan\", \"berkenaan\", \"berlainan\", \"berlalu\", \"berlangsung\", \"berlebihan\", \"bermacam\", \"bermacam-macam\", \"bermaksud\", \"bermula\", \"bersama\", \"bersama-sama\", \"bersiap\", \"bersiap-siap\", \"bertanya\", \"bertanya-tanya\", \"berturut\", \"berturut-turut\", \"bertutur\", \"berujar\", \"berupa\", \"besar\", \"betul\", \"betulkah\", \"biasa\", \"biasanya\", \"bila\", \"bilakah\", \"bisa\", \"bisakah\", \"boleh\", \"bolehkah\", \"bolehlah\", \"buat\", \"bukan\", \"bukankah\", \"bukanlah\", \"bukannya\", \"bulan\", \"bung\", \"cara\", \"caranya\", \"cukup\", \"cukupkah\", \"cukuplah\", \"cuma\", \"dahulu\", \"dalam\", \"dan\", \"dapat\", \"dari\", \"daripada\", \"datang\", \"dekat\", \"demi\", \"demikian\", \"demikianlah\", \"dengan\", \"depan\", \"di\", \"dia\", \"diakhiri\", \"diakhirinya\", \"dialah\", \"diantara\", \"diantaranya\", \"diberi\", \"diberikan\", \"diberikannya\", \"dibuat\", \"dibuatnya\", \"didapat\", \"didatangkan\", \"digunakan\", \"diibaratkan\", \"diibaratkannya\", \"diingat\", \"diingatkan\", \"diinginkan\", \"dijawab\", \"dijelaskan\", \"dijelaskannya\", \"dikarenakan\", \"dikatakan\", \"dikatakannya\", \"dikerjakan\", \"diketahui\", \"diketahuinya\", \"dikira\", \"dilakukan\", \"dilalui\", \"dilihat\", \"dimaksud\", \"dimaksudkan\", \"dimaksudkannya\", \"dimaksudnya\", \"diminta\", \"dimintai\", \"dimisalkan\", \"dimulai\", \"dimulailah\", \"dimulainya\", \"dimungkinkan\", \"dini\", \"dipastikan\", \"diperbuat\", \"diperbuatnya\", \"dipergunakan\", \"diperkirakan\", \"diperlihatkan\", \"diperlukan\", \"diperlukannya\", \"dipersoalkan\", \"dipertanyakan\", \"dipunyai\", \"diri\", \"dirinya\", \"disampaikan\", \"disebut\", \"disebutkan\", \"disebutkannya\", \"disini\", \"disinilah\", \"ditambahkan\", \"ditandaskan\", \"ditanya\", \"ditanyai\", \"ditanyakan\", \"ditegaskan\", \"ditujukan\", \"ditunjuk\", \"ditunjuki\", \"ditunjukkan\", \"ditunjukkannya\", \"ditunjuknya\", \"dituturkan\", \"dituturkannya\", \"diucapkan\", \"diucapkannya\", \"diungkapkan\", \"dong\", \"dua\", \"dulu\", \"empat\", \"enggak\", \"enggaknya\", \"entah\", \"entahlah\", \"guna\", \"gunakan\", \"hal\", \"hampir\", \"hanya\", \"hanyalah\", \"hari\", \"harus\", \"haruslah\", \"harusnya\", \"hendak\", \"hendaklah\", \"hendaknya\", \"hingga\", \"ia\", \"ialah\", \"ibarat\", \"ibaratkan\", \"ibaratnya\", \"ibu\", \"ikut\", \"ingat\", \"ingat-ingat\", \"ingin\", \"inginkah\", \"inginkan\", \"ini\", \"inikah\", \"inilah\", \"itu\", \"itukah\", \"itulah\", \"jadi\", \"jadilah\", \"jadinya\", \"jangan\", \"jangankan\", \"janganlah\", \"jauh\", \"jawab\", \"jawaban\", \"jawabnya\", \"jelas\", \"jelaskan\", \"jelaslah\", \"jelasnya\", \"jika\", \"jikalau\", \"juga\", \"jumlah\", \"jumlahnya\", \"justru\", \"kala\", \"kalau\", \"kalaulah\", \"kalaupun\", \"kalian\", \"kami\", \"kamilah\", \"kamu\", \"kamulah\", \"kan\", \"kapan\", \"kapankah\", \"kapanpun\", \"karena\", \"karenanya\", \"kasus\", \"kata\", \"katakan\", \"katakanlah\", \"katanya\", \"ke\", \"keadaan\", \"kebetulan\", \"kecil\", \"kedua\", \"keduanya\", \"keinginan\", \"kelamaan\", \"kelihatan\", \"kelihatannya\", \"kelima\", \"keluar\", \"kembali\", \"kemudian\", \"kemungkinan\", \"kemungkinannya\", \"kenapa\", \"kepada\", \"kepadanya\", \"kesampaian\", \"keseluruhan\", \"keseluruhannya\", \"keterlaluan\", \"ketika\", \"khususnya\", \"kini\", \"kinilah\", \"kira\", \"kira-kira\", \"kiranya\", \"kita\", \"kitalah\", \"kok\", \"kurang\", \"lagi\", \"lagian\", \"lah\", \"lain\", \"lainnya\", \"lalu\", \"lama\", \"lamanya\", \"lanjut\", \"lanjutnya\", \"lebih\", \"lewat\", \"lima\", \"luar\", \"macam\", \"maka\", \"makanya\", \"makin\", \"malah\", \"malahan\", \"mampu\", \"mampukah\", \"mana\", \"manakala\", \"manalagi\", \"masa\", \"masalah\", \"masalahnya\", \"masih\", \"masihkah\", \"masing\", \"masing-masing\", \"mau\", \"maupun\", \"melainkan\", \"melakukan\", \"melalui\", \"melihat\", \"melihatnya\", \"memang\", \"memastikan\", \"memberi\", \"memberikan\", \"membuat\", \"memerlukan\", \"memihak\", \"meminta\", \"memintakan\", \"memisalkan\", \"memperbuat\", \"mempergunakan\", \"memperkirakan\", \"memperlihatkan\", \"mempersiapkan\", \"mempersoalkan\", \"mempertanyakan\", \"mempunyai\", \"memulai\", \"memungkinkan\", \"menaiki\", \"menambahkan\", \"menandaskan\", \"menanti\", \"menanti-nanti\", \"menantikan\", \"menanya\", \"menanyai\", \"menanyakan\", \"mendapat\", \"mendapatkan\", \"mendatang\", \"mendatangi\", \"mendatangkan\", \"menegaskan\", \"mengakhiri\", \"mengapa\", \"mengatakan\", \"mengatakannya\", \"mengenai\", \"mengerjakan\", \"mengetahui\", \"menggunakan\", \"menghendaki\", \"mengibaratkan\", \"mengibaratkannya\", \"mengingat\", \"mengingatkan\", \"menginginkan\", \"mengira\", \"mengiranya\", \"mengucapkan\", \"mengucapkannya\", \"mengungkapkan\", \"menjadi\", \"menjawab\", \"menjelaskan\", \"menuju\", \"menunjuk\", \"menunjuki\", \"menunjukkan\", \"menunjuknya\", \"menurut\", \"menuturkan\", \"menyampaikan\", \"menyangkut\", \"menyatakan\", \"menyebutkan\", \"menyeluruh\", \"menyiapkan\", \"merasa\", \"mereka\", \"merekalah\", \"merupakan\", \"meski\", \"meskipun\", \"meyakini\", \"meyakinkan\", \"minta\", \"mirip\", \"misal\", \"misalkan\", \"misalnya\", \"mula\", \"mulai\", \"mulailah\", \"mulanya\", \"mungkin\", \"mungkinkah\", \"nah\", \"naik\", \"namun\", \"nanti\", \"nantinya\", \"nyaris\", \"nyatanya\", \"oleh\", \"olehnya\", \"pada\", \"padahal\", \"padanya\", \"pak\", \"paling\", \"panjang\", \"pantas\", \"para\", \"pasti\", \"pastilah\", \"penting\", \"pentingnya\", \"per\", \"percuma\", \"perlu\", \"perlukah\", \"perlunya\", \"pernah\", \"persoalan\", \"pertama\", \"pertama-tama\", \"pertanyaan\", \"pertanyakan\", \"pihak\", \"pihaknya\", \"pukul\", \"pula\", \"pun\", \"punya\", \"rasa\", \"rasanya\", \"rupa\", \"rupanya\", \"saat\", \"saatnya\", \"saja\", \"sajalah\", \"saling\", \"sama\", \"sama-sama\", \"sambil\", \"sampai\", \"sampai-sampai\", \"sampaikan\", \"sana\", \"sangat\", \"sangatlah\", \"satu\", \"saya\", \"sayalah\", \"se\", \"sebab\", \"sebabnya\", \"sebagai\", \"sebagaimana\", \"sebagainya\", \"sebagian\", \"sebaik\", \"sebaik-baiknya\", \"sebaiknya\", \"sebaliknya\", \"sebanyak\", \"sebegini\", \"sebegitu\", \"sebelum\", \"sebelumnya\", \"sebenarnya\", \"seberapa\", \"sebesar\", \"sebetulnya\", \"sebisanya\", \"sebuah\", \"sebut\", \"sebutlah\", \"sebutnya\", \"secara\", \"secukupnya\", \"sedang\", \"sedangkan\", \"sedemikian\", \"sedikit\", \"sedikitnya\", \"seenaknya\", \"segala\", \"segalanya\", \"segera\", \"seharusnya\", \"sehingga\", \"seingat\", \"sejak\", \"sejauh\", \"sejenak\", \"sejumlah\", \"sekadar\", \"sekadarnya\", \"sekali\", \"sekali-kali\", \"sekalian\", \"sekaligus\", \"sekalipun\", \"sekarang\", \"sekaranglah\", \"sekecil\", \"seketika\", \"sekiranya\", \"sekitar\", \"sekitarnya\", \"sekurang-kurangnya\", \"sekurangnya\", \"sela\", \"selain\", \"selaku\", \"selalu\", \"selama\", \"selama-lamanya\", \"selamanya\", \"selanjutnya\", \"seluruh\", \"seluruhnya\", \"semacam\", \"semakin\", \"semampu\", \"semampunya\", \"semasa\", \"semasih\", \"semata\", \"semata-mata\", \"semaunya\", \"sementara\", \"semisal\", \"semisalnya\", \"sempat\", \"semua\", \"semuanya\", \"semula\", \"sendiri\", \"sendirian\", \"sendirinya\", \"seolah\", \"seolah-olah\", \"seorang\", \"sepanjang\", \"sepantasnya\", \"sepantasnyalah\", \"seperlunya\", \"sepertinya\", \"sepihak\", \"sering\", \"seringnya\", \"serta\", \"serupa\", \"sesaat\", \"sesama\", \"sesampai\", \"sesegera\", \"sesekali\", \"seseorang\", \"sesuatu\", \"sesuatunya\", \"sesudah\", \"sesudahnya\", \"setelah\", \"setempat\", \"setengah\", \"seterusnya\", \"setiap\", \"setiba\", \"setibanya\", \"setidak-tidaknya\", \"setidaknya\", \"setinggi\", \"seusai\", \"sewaktu\", \"siap\", \"siapa\", \"siapakah\", \"siapapun\", \"sini\", \"sinilah\", \"soal\", \"soalnya\", \"suatu\", \"sudah\", \"sudahkah\", \"sudahlah\", \"supaya\", \"tadi\", \"tadinya\", \"tahu\", \"tahun\", \"tak\", \"tambah\", \"tambahnya\", \"tampak\", \"tampaknya\", \"tandas\", \"tandasnya\", \"tanpa\", \"tanya\", \"tanyakan\", \"tanyanya\", \"tapi\", \"tegas\", \"tegasnya\", \"telah\", \"tempat\", \"tengah\", \"tentang\", \"tentu\", \"tentulah\", \"tentunya\", \"tepat\", \"terakhir\", \"terasa\", \"terbanyak\", \"terberi\", \"terhadap\", \"terhadapnya\", \"terjadi\", \"terjadilah\", \"terjadinya\", \"terkira\", \"terlalu\", \"terlebih\", \"terlihat\", \"termasuk\", \"ternyata\", \"tersampaikan\", \"tersebut\", \"tersebutlah\", \"tertentu\", \"tertutup\", \"tertuju\", \"terus\", \"terutama\", \"tetap\", \"tetapi\", \"tiap\", \"tiba\", \"tiba-tiba\", \"tidak\", \"tidakkah\", \"tidaklah\", \"tinggi\", \"toh\", \"tunjuk\", \"turut\", \"tutur\", \"tuturnya\", \"ucap\", \"ucapnya\", \"ujar\", \"ujarnya\", \"umum\", \"umumnya\", \"ungkap\", \"ungkapnya\", \"untuk\", \"usah\", \"usai\", \"waduh\", \"wah\", \"wahai\", \"waktu\", \"waktunya\", \"walau\", \"walaupun\", \"wong\", \"yaitu\", \"yakin\", \"yakni\", \"yang\"\n",
        "    ]\n",
        "    for doc in list_of_tokenize_doc:\n",
        "        temp = []\n",
        "        for word in doc:\n",
        "            if word in stopwords:\n",
        "                continue\n",
        "            temp.append(word)\n",
        "        result.append(temp)\n",
        "    return result\n",
        "\n",
        "\n",
        "def stemming(list_of_tokenize_doc):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    result = []\n",
        "    for doc in list_of_tokenize_doc:\n",
        "        temp = []\n",
        "        for word in doc:\n",
        "            temp.append(stemmer.stem(word))\n",
        "        result.append(temp)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hD6So4cUe5mm"
      },
      "outputs": [],
      "source": [
        "case_folding_lyrics = case_folding(lyrics)\n",
        "normalization_lyrics = normalization(case_folding_lyrics)\n",
        "tokenization_lyrics = tokenization(normalization_lyrics)\n",
        "stopword_removal_lyrics = stopword_removal(tokenization_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fb5Xq_nYfGUA"
      },
      "outputs": [],
      "source": [
        "stemming_lyrics = stemming(stopword_removal_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jdU8dAUjqhBY"
      },
      "outputs": [],
      "source": [
        "# split datset\n",
        "temp = []\n",
        "for index in range(len(stemming_lyrics)):\n",
        "    temp.append({\"lyrics\": stemming_lyrics[index], \"label\": label[index]})\n",
        "\n",
        "random.shuffle(temp)\n",
        "\n",
        "train_data = temp[: int(0.8 * len(temp))]\n",
        "# train_data = temp\n",
        "test_data = temp[int(0.8 * len(temp)) :]\n",
        "\n",
        "\n",
        "train_lyrics = [data[\"lyrics\"] for data in train_data]\n",
        "train_label = [data[\"label\"] for data in train_data]\n",
        "\n",
        "test_lyrics = [data[\"lyrics\"] for data in test_data]\n",
        "test_label = [data[\"label\"] for data in test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DhhdNFhrKhu",
        "outputId": "17b89a19-5a9f-48c3-a59f-f5a7e30e9d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_clean_data = [' '.join(sentence) for sentence in stemming_lyrics]\n",
        "tfidf = TFIDF()\n",
        "X_train = tfidf.fit_transform(train_clean_data)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppkmxwmltMnp",
        "outputId": "aad95c43-b585-4984-b305-010ab36e1b37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_clean_data = [' '.join(sentence) for sentence in test_lyrics]\n",
        "X_test = tfidf.transform(test_clean_data)\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KiyX90fXuMuM"
      },
      "outputs": [],
      "source": [
        "mnb = MultinomialNaiveBayes()\n",
        "mnb.fit(X_train, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IofFGJHMyg9s"
      },
      "outputs": [],
      "source": [
        "y = np.array(label)\n",
        "y = np.where(y <= 0, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DgSSVd1uo3iU"
      },
      "outputs": [],
      "source": [
        "svm = SVM(C=1)\n",
        "svm.fit(X_train,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Lp1fPCAFdg",
        "outputId": "347f2c55-1c62-438f-92c8-18010f44bf12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['output/tfidf.joblib']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(svm, 'output/model_svm.joblib')\n",
        "joblib.dump(mnb, 'output/model_mnb.joblib')\n",
        "joblib.dump(tfidf, 'output/tfidf.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_tfidf = joblib.load('output/tfidf.joblib')\n",
        "load_mnb = joblib.load('output/model_mnb.joblib')\n",
        "load_svm = joblib.load('output/model_svm.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluation import accuracy, precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_mnb_pred = load_mnb.predict(X_test)\n",
        "load_svm_pred = load_svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm_accuracy = accuracy(test_label, load_svm_pred)\n",
        "svm_precision = precision(test_label, load_svm_pred)\n",
        "svm_recall = recall(test_label, load_svm_pred)\n",
        "svm_f1_score = f1_score(test_label, load_svm_pred)\n",
        "\n",
        "mnb_accuracy = accuracy(test_label, load_mnb_pred)\n",
        "mnb_precision = precision(test_label, load_mnb_pred)\n",
        "mnb_recall = recall(test_label, load_mnb_pred)\n",
        "mnb_f1_score = f1_score(test_label, load_mnb_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM\n",
            "Accuracy: 0.951048951048951\n",
            "Precision: 0.9322033898305084\n",
            "Recall: 0.9482758620689655\n",
            "F1 Score: 0.94017094017094\n"
          ]
        }
      ],
      "source": [
        "print(\"SVM\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1 Score:\", svm_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes\n",
            "Accuracy: 0.8951048951048951\n",
            "Precision: 0.9777777777777777\n",
            "Recall: 0.7586206896551724\n",
            "F1 Score: 0.854368932038835\n"
          ]
        }
      ],
      "source": [
        "print(\"Multinomial Naive Bayes\")\n",
        "print(f\"Accuracy: {mnb_accuracy}\")\n",
        "print(f\"Precision: {mnb_precision}\")\n",
        "print(f\"Recall: {mnb_recall}\")\n",
        "print(f\"F1 Score: {mnb_f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
