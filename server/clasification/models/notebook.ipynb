{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import TFIDF, MultinomialNaiveBayes, SVM\n",
        "from kfold_validation import KFoldValidation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "lyrics = []\n",
        "label = []\n",
        "title = []\n",
        "artist = []\n",
        "\n",
        "with open(\"dataset/clean_dataset.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for doc in reader:\n",
        "        lyrics.append(doc[\"lyrics\"])\n",
        "        label.append(int(doc[\"label\"]))\n",
        "        title.append(doc[\"song_name\"])\n",
        "        artist.append(doc[\"artist\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t_3np0Oeesp0"
      },
      "outputs": [],
      "source": [
        "def case_folding(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(doc.lower())\n",
        "    return temp\n",
        "\n",
        "\n",
        "def normalization(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(\" \".join(re.findall(r\"[a-zA-Z]+\", doc)))\n",
        "    return temp\n",
        "\n",
        "\n",
        "def tokenization(list_doc):\n",
        "    temp = []\n",
        "    for doc in list_doc:\n",
        "        temp.append(doc.split())\n",
        "    return temp\n",
        "\n",
        "\n",
        "def stopword_removal(list_of_tokenize_doc):\n",
        "    result = []\n",
        "    stopwords = [\n",
        "        \"ada\", \"adalah\", \"adanya\", \"adapun\", \"agak\", \"agaknya\", \"agar\", \"akan\", \"akankah\", \"akhir\", \"akhiri\", \"akhirnya\", \"aku\", \"akulah\", \"amat\", \"amatlah\", \"anda\", \"andalah\", \"antar\", \"antara\", \"antaranya\", \"apa\", \"apaan\", \"apabila\", \"apakah\", \"apalagi\", \"apatah\", \"artinya\", \"asal\", \"asalkan\", \"atas\", \"atau\", \"ataukah\", \"ataupun\", \"awal\", \"awalnya\", \"bagai\", \"bagaikan\", \"bagaimana\", \"bagaimanakah\", \"bagaimanapun\", \"bagi\", \"bagian\", \"bahkan\", \"bahwa\", \"bahwasanya\", \"baik\", \"bakal\", \"bakalan\", \"balik\", \"banyak\", \"bapak\", \"baru\", \"bawah\", \"beberapa\", \"begini\", \"beginian\", \"beginikah\", \"beginilah\", \"begitu\", \"begitukah\", \"begitulah\", \"begitupun\", \"bekerja\", \"belakang\", \"belakangan\", \"belum\", \"belumlah\", \"benar\", \"benarkah\", \"benarlah\", \"berada\", \"berakhir\", \"berakhirlah\", \"berakhirnya\", \"berapa\", \"berapakah\", \"berapalah\", \"berapapun\", \"berarti\", \"berawal\", \"berbagai\", \"berdatangan\", \"beri\", \"berikan\", \"berikut\", \"berikutnya\", \"berjumlah\", \"berkali-kali\", \"berkata\", \"berkehendak\", \"berkeinginan\", \"berkenaan\", \"berlainan\", \"berlalu\", \"berlangsung\", \"berlebihan\", \"bermacam\", \"bermacam-macam\", \"bermaksud\", \"bermula\", \"bersama\", \"bersama-sama\", \"bersiap\", \"bersiap-siap\", \"bertanya\", \"bertanya-tanya\", \"berturut\", \"berturut-turut\", \"bertutur\", \"berujar\", \"berupa\", \"besar\", \"betul\", \"betulkah\", \"biasa\", \"biasanya\", \"bila\", \"bilakah\", \"bisa\", \"bisakah\", \"boleh\", \"bolehkah\", \"bolehlah\", \"buat\", \"bukan\", \"bukankah\", \"bukanlah\", \"bukannya\", \"bulan\", \"bung\", \"cara\", \"caranya\", \"cukup\", \"cukupkah\", \"cukuplah\", \"cuma\", \"dahulu\", \"dalam\", \"dan\", \"dapat\", \"dari\", \"daripada\", \"datang\", \"dekat\", \"demi\", \"demikian\", \"demikianlah\", \"dengan\", \"depan\", \"di\", \"dia\", \"diakhiri\", \"diakhirinya\", \"dialah\", \"diantara\", \"diantaranya\", \"diberi\", \"diberikan\", \"diberikannya\", \"dibuat\", \"dibuatnya\", \"didapat\", \"didatangkan\", \"digunakan\", \"diibaratkan\", \"diibaratkannya\", \"diingat\", \"diingatkan\", \"diinginkan\", \"dijawab\", \"dijelaskan\", \"dijelaskannya\", \"dikarenakan\", \"dikatakan\", \"dikatakannya\", \"dikerjakan\", \"diketahui\", \"diketahuinya\", \"dikira\", \"dilakukan\", \"dilalui\", \"dilihat\", \"dimaksud\", \"dimaksudkan\", \"dimaksudkannya\", \"dimaksudnya\", \"diminta\", \"dimintai\", \"dimisalkan\", \"dimulai\", \"dimulailah\", \"dimulainya\", \"dimungkinkan\", \"dini\", \"dipastikan\", \"diperbuat\", \"diperbuatnya\", \"dipergunakan\", \"diperkirakan\", \"diperlihatkan\", \"diperlukan\", \"diperlukannya\", \"dipersoalkan\", \"dipertanyakan\", \"dipunyai\", \"diri\", \"dirinya\", \"disampaikan\", \"disebut\", \"disebutkan\", \"disebutkannya\", \"disini\", \"disinilah\", \"ditambahkan\", \"ditandaskan\", \"ditanya\", \"ditanyai\", \"ditanyakan\", \"ditegaskan\", \"ditujukan\", \"ditunjuk\", \"ditunjuki\", \"ditunjukkan\", \"ditunjukkannya\", \"ditunjuknya\", \"dituturkan\", \"dituturkannya\", \"diucapkan\", \"diucapkannya\", \"diungkapkan\", \"dong\", \"dua\", \"dulu\", \"empat\", \"enggak\", \"enggaknya\", \"entah\", \"entahlah\", \"guna\", \"gunakan\", \"hal\", \"hampir\", \"hanya\", \"hanyalah\", \"hari\", \"harus\", \"haruslah\", \"harusnya\", \"hendak\", \"hendaklah\", \"hendaknya\", \"hingga\", \"ia\", \"ialah\", \"ibarat\", \"ibaratkan\", \"ibaratnya\", \"ibu\", \"ikut\", \"ingat\", \"ingat-ingat\", \"ingin\", \"inginkah\", \"inginkan\", \"ini\", \"inikah\", \"inilah\", \"itu\", \"itukah\", \"itulah\", \"jadi\", \"jadilah\", \"jadinya\", \"jangan\", \"jangankan\", \"janganlah\", \"jauh\", \"jawab\", \"jawaban\", \"jawabnya\", \"jelas\", \"jelaskan\", \"jelaslah\", \"jelasnya\", \"jika\", \"jikalau\", \"juga\", \"jumlah\", \"jumlahnya\", \"justru\", \"kala\", \"kalau\", \"kalaulah\", \"kalaupun\", \"kalian\", \"kami\", \"kamilah\", \"kamu\", \"kamulah\", \"kan\", \"kapan\", \"kapankah\", \"kapanpun\", \"karena\", \"karenanya\", \"kasus\", \"kata\", \"katakan\", \"katakanlah\", \"katanya\", \"ke\", \"keadaan\", \"kebetulan\", \"kecil\", \"kedua\", \"keduanya\", \"keinginan\", \"kelamaan\", \"kelihatan\", \"kelihatannya\", \"kelima\", \"keluar\", \"kembali\", \"kemudian\", \"kemungkinan\", \"kemungkinannya\", \"kenapa\", \"kepada\", \"kepadanya\", \"kesampaian\", \"keseluruhan\", \"keseluruhannya\", \"keterlaluan\", \"ketika\", \"khususnya\", \"kini\", \"kinilah\", \"kira\", \"kira-kira\", \"kiranya\", \"kita\", \"kitalah\", \"kok\", \"kurang\", \"lagi\", \"lagian\", \"lah\", \"lain\", \"lainnya\", \"lalu\", \"lama\", \"lamanya\", \"lanjut\", \"lanjutnya\", \"lebih\", \"lewat\", \"lima\", \"luar\", \"macam\", \"maka\", \"makanya\", \"makin\", \"malah\", \"malahan\", \"mampu\", \"mampukah\", \"mana\", \"manakala\", \"manalagi\", \"masa\", \"masalah\", \"masalahnya\", \"masih\", \"masihkah\", \"masing\", \"masing-masing\", \"mau\", \"maupun\", \"melainkan\", \"melakukan\", \"melalui\", \"melihat\", \"melihatnya\", \"memang\", \"memastikan\", \"memberi\", \"memberikan\", \"membuat\", \"memerlukan\", \"memihak\", \"meminta\", \"memintakan\", \"memisalkan\", \"memperbuat\", \"mempergunakan\", \"memperkirakan\", \"memperlihatkan\", \"mempersiapkan\", \"mempersoalkan\", \"mempertanyakan\", \"mempunyai\", \"memulai\", \"memungkinkan\", \"menaiki\", \"menambahkan\", \"menandaskan\", \"menanti\", \"menanti-nanti\", \"menantikan\", \"menanya\", \"menanyai\", \"menanyakan\", \"mendapat\", \"mendapatkan\", \"mendatang\", \"mendatangi\", \"mendatangkan\", \"menegaskan\", \"mengakhiri\", \"mengapa\", \"mengatakan\", \"mengatakannya\", \"mengenai\", \"mengerjakan\", \"mengetahui\", \"menggunakan\", \"menghendaki\", \"mengibaratkan\", \"mengibaratkannya\", \"mengingat\", \"mengingatkan\", \"menginginkan\", \"mengira\", \"mengiranya\", \"mengucapkan\", \"mengucapkannya\", \"mengungkapkan\", \"menjadi\", \"menjawab\", \"menjelaskan\", \"menuju\", \"menunjuk\", \"menunjuki\", \"menunjukkan\", \"menunjuknya\", \"menurut\", \"menuturkan\", \"menyampaikan\", \"menyangkut\", \"menyatakan\", \"menyebutkan\", \"menyeluruh\", \"menyiapkan\", \"merasa\", \"mereka\", \"merekalah\", \"merupakan\", \"meski\", \"meskipun\", \"meyakini\", \"meyakinkan\", \"minta\", \"mirip\", \"misal\", \"misalkan\", \"misalnya\", \"mula\", \"mulai\", \"mulailah\", \"mulanya\", \"mungkin\", \"mungkinkah\", \"nah\", \"naik\", \"namun\", \"nanti\", \"nantinya\", \"nyaris\", \"nyatanya\", \"oleh\", \"olehnya\", \"pada\", \"padahal\", \"padanya\", \"pak\", \"paling\", \"panjang\", \"pantas\", \"para\", \"pasti\", \"pastilah\", \"penting\", \"pentingnya\", \"per\", \"percuma\", \"perlu\", \"perlukah\", \"perlunya\", \"pernah\", \"persoalan\", \"pertama\", \"pertama-tama\", \"pertanyaan\", \"pertanyakan\", \"pihak\", \"pihaknya\", \"pukul\", \"pula\", \"pun\", \"punya\", \"rasa\", \"rasanya\", \"rupa\", \"rupanya\", \"saat\", \"saatnya\", \"saja\", \"sajalah\", \"saling\", \"sama\", \"sama-sama\", \"sambil\", \"sampai\", \"sampai-sampai\", \"sampaikan\", \"sana\", \"sangat\", \"sangatlah\", \"satu\", \"saya\", \"sayalah\", \"se\", \"sebab\", \"sebabnya\", \"sebagai\", \"sebagaimana\", \"sebagainya\", \"sebagian\", \"sebaik\", \"sebaik-baiknya\", \"sebaiknya\", \"sebaliknya\", \"sebanyak\", \"sebegini\", \"sebegitu\", \"sebelum\", \"sebelumnya\", \"sebenarnya\", \"seberapa\", \"sebesar\", \"sebetulnya\", \"sebisanya\", \"sebuah\", \"sebut\", \"sebutlah\", \"sebutnya\", \"secara\", \"secukupnya\", \"sedang\", \"sedangkan\", \"sedemikian\", \"sedikit\", \"sedikitnya\", \"seenaknya\", \"segala\", \"segalanya\", \"segera\", \"seharusnya\", \"sehingga\", \"seingat\", \"sejak\", \"sejauh\", \"sejenak\", \"sejumlah\", \"sekadar\", \"sekadarnya\", \"sekali\", \"sekali-kali\", \"sekalian\", \"sekaligus\", \"sekalipun\", \"sekarang\", \"sekaranglah\", \"sekecil\", \"seketika\", \"sekiranya\", \"sekitar\", \"sekitarnya\", \"sekurang-kurangnya\", \"sekurangnya\", \"sela\", \"selain\", \"selaku\", \"selalu\", \"selama\", \"selama-lamanya\", \"selamanya\", \"selanjutnya\", \"seluruh\", \"seluruhnya\", \"semacam\", \"semakin\", \"semampu\", \"semampunya\", \"semasa\", \"semasih\", \"semata\", \"semata-mata\", \"semaunya\", \"sementara\", \"semisal\", \"semisalnya\", \"sempat\", \"semua\", \"semuanya\", \"semula\", \"sendiri\", \"sendirian\", \"sendirinya\", \"seolah\", \"seolah-olah\", \"seorang\", \"sepanjang\", \"sepantasnya\", \"sepantasnyalah\", \"seperlunya\", \"sepertinya\", \"sepihak\", \"sering\", \"seringnya\", \"serta\", \"serupa\", \"sesaat\", \"sesama\", \"sesampai\", \"sesegera\", \"sesekali\", \"seseorang\", \"sesuatu\", \"sesuatunya\", \"sesudah\", \"sesudahnya\", \"setelah\", \"setempat\", \"setengah\", \"seterusnya\", \"setiap\", \"setiba\", \"setibanya\", \"setidak-tidaknya\", \"setidaknya\", \"setinggi\", \"seusai\", \"sewaktu\", \"siap\", \"siapa\", \"siapakah\", \"siapapun\", \"sini\", \"sinilah\", \"soal\", \"soalnya\", \"suatu\", \"sudah\", \"sudahkah\", \"sudahlah\", \"supaya\", \"tadi\", \"tadinya\", \"tahu\", \"tahun\", \"tak\", \"tambah\", \"tambahnya\", \"tampak\", \"tampaknya\", \"tandas\", \"tandasnya\", \"tanpa\", \"tanya\", \"tanyakan\", \"tanyanya\", \"tapi\", \"tegas\", \"tegasnya\", \"telah\", \"tempat\", \"tengah\", \"tentang\", \"tentu\", \"tentulah\", \"tentunya\", \"tepat\", \"terakhir\", \"terasa\", \"terbanyak\", \"terberi\", \"terhadap\", \"terhadapnya\", \"terjadi\", \"terjadilah\", \"terjadinya\", \"terkira\", \"terlalu\", \"terlebih\", \"terlihat\", \"termasuk\", \"ternyata\", \"tersampaikan\", \"tersebut\", \"tersebutlah\", \"tertentu\", \"tertutup\", \"tertuju\", \"terus\", \"terutama\", \"tetap\", \"tetapi\", \"tiap\", \"tiba\", \"tiba-tiba\", \"tidak\", \"tidakkah\", \"tidaklah\", \"tinggi\", \"toh\", \"tunjuk\", \"turut\", \"tutur\", \"tuturnya\", \"ucap\", \"ucapnya\", \"ujar\", \"ujarnya\", \"umum\", \"umumnya\", \"ungkap\", \"ungkapnya\", \"untuk\", \"usah\", \"usai\", \"waduh\", \"wah\", \"wahai\", \"waktu\", \"waktunya\", \"walau\", \"walaupun\", \"wong\", \"yaitu\", \"yakin\", \"yakni\", \"yang\"\n",
        "    ]\n",
        "    for doc in list_of_tokenize_doc:\n",
        "        temp = []\n",
        "        for word in doc:\n",
        "            if word in stopwords:\n",
        "                continue\n",
        "            temp.append(word)\n",
        "        result.append(temp)\n",
        "    return result\n",
        "\n",
        "\n",
        "def stemming(list_of_tokenize_doc):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    result = []\n",
        "    for doc in list_of_tokenize_doc:\n",
        "        temp = []\n",
        "        for word in doc:\n",
        "            temp.append(stemmer.stem(word))\n",
        "        result.append(temp)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hD6So4cUe5mm"
      },
      "outputs": [],
      "source": [
        "case_folding_lyrics = case_folding(lyrics)\n",
        "normalization_lyrics = normalization(case_folding_lyrics)\n",
        "tokenization_lyrics = tokenization(normalization_lyrics)\n",
        "stopword_removal_lyrics = stopword_removal(tokenization_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Fb5Xq_nYfGUA"
      },
      "outputs": [],
      "source": [
        "stemming_lyrics = stemming(stopword_removal_lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "TFIDF_vectorizer = TFIDF()\n",
        "X = TFIDF_vectorizer.fit_transform([' '.join(sentence) for sentence in stemming_lyrics])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "mnb = MultinomialNaiveBayes()\n",
        "svm = SVM(C=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Ode\\Documents\\GitHub\\lyrics-classifier\\server\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Ode\\Documents\\GitHub\\lyrics-classifier\\server\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Ode\\Documents\\GitHub\\lyrics-classifier\\server\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Ode\\Documents\\GitHub\\lyrics-classifier\\server\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Ode\\Documents\\GitHub\\lyrics-classifier\\server\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'naive_bayes': {'metrics': {'accuracy': {'mean': np.float64(0.6724120949473061),\n",
              "    'std': np.float64(0.045323236243292375),\n",
              "    'scores': [0.5874125874125874,\n",
              "     0.6690140845070423,\n",
              "     0.6901408450704225,\n",
              "     0.7183098591549296,\n",
              "     0.6971830985915493]},\n",
              "   'precision': {'mean': np.float64(0.7272008552125917),\n",
              "    'std': np.float64(0.025248909447121923),\n",
              "    'scores': [0.6906451080679755,\n",
              "     0.7277888924455825,\n",
              "     0.7647967349551856,\n",
              "     0.7116203715801301,\n",
              "     0.7411531690140846]},\n",
              "   'recall': {'mean': np.float64(0.6724120949473061),\n",
              "    'std': np.float64(0.045323236243292375),\n",
              "    'scores': [0.5874125874125874,\n",
              "     0.6690140845070423,\n",
              "     0.6901408450704225,\n",
              "     0.7183098591549296,\n",
              "     0.6971830985915493]},\n",
              "   'f1': {'mean': np.float64(0.6481979229751721),\n",
              "    'std': np.float64(0.05440960012816641),\n",
              "    'scores': [0.5494130993008454,\n",
              "     0.6418482762614751,\n",
              "     0.6647699166340425,\n",
              "     0.7125661772050744,\n",
              "     0.6723921454744232]}},\n",
              "  'final_model': <model.MultinomialNaiveBayes at 0x1eb4517d5b0>},\n",
              " 'svm': {'metrics': {'accuracy': {'mean': np.float64(0.4696542893725992),\n",
              "    'std': np.float64(0.05898868614693865),\n",
              "    'scores': [0.5454545454545454,\n",
              "     0.4859154929577465,\n",
              "     0.49295774647887325,\n",
              "     0.36619718309859156,\n",
              "     0.45774647887323944]},\n",
              "   'precision': {'mean': np.float64(0.22405481661942322),\n",
              "    'std': np.float64(0.05330021994878613),\n",
              "    'scores': [0.29752066115702475,\n",
              "     0.2361138662963698,\n",
              "     0.24300733981352907,\n",
              "     0.13410037690934337,\n",
              "     0.20953183892084903]},\n",
              "   'recall': {'mean': np.float64(0.4696542893725992),\n",
              "    'std': np.float64(0.05898868614693865),\n",
              "    'scores': [0.5454545454545454,\n",
              "     0.4859154929577465,\n",
              "     0.49295774647887325,\n",
              "     0.36619718309859156,\n",
              "     0.45774647887323944]},\n",
              "   'f1': {'mean': np.float64(0.30243058967539815),\n",
              "    'std': np.float64(0.06176935813742261),\n",
              "    'scores': [0.3850267379679145,\n",
              "     0.3178025498965356,\n",
              "     0.32553813446718044,\n",
              "     0.196311891970379,\n",
              "     0.2874736340749813]}},\n",
              "  'final_model': <model.SVM at 0x1eb4517e270>},\n",
              " 'better_model_name': 'Naive Bayes',\n",
              " 'better_model': <model.MultinomialNaiveBayes at 0x1eb4517d5b0>}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = KFoldValidation(mnb, svm, X, np.array(label), n_splits=5)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save The Result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['output/tfidf.joblib']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the result into json file\n",
        "import json\n",
        "\n",
        "results_dict = {\n",
        "    \"Multinomial Naive Bayes\": results[\"naive_bayes\"],\n",
        "    \"SVM\": results[\"svm\"]\n",
        "}\n",
        "\n",
        "results_dict[\"Multinomial Naive Bayes\"][\"final_model\"] = str(mnb)\n",
        "results_dict[\"SVM\"][\"final_model\"] = str(svm)\n",
        "\n",
        "with open(\"output/results.json\", \"w\") as outfile:\n",
        "    json.dump(results_dict, outfile, indent=4)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(mnb, \"output/model_mnb.joblib\")\n",
        "joblib.dump(svm, \"output/model_svm.joblib\")\n",
        "joblib.dump(TFIDF_vectorizer, \"output/tfidf.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
